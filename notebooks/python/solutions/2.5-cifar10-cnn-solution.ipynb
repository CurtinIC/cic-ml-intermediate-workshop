{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs, though it is still underfitting at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "keras.__version__\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters --------------------------------------------------------------\n",
    "# It takes ~4 minutes to run each epoch, adjust the number to match time left\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "data_augmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation --------------------------------------------------------\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load the data\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "\n",
    "# Feature scale RGB values in test and train inputs  \n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model ----------------------------------------------------------\n",
    "\n",
    "# Initialize sequential model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Start with hidden 2D convolutional layer being fed 32x32 pixel images\n",
    "model.add(layers.Conv2D(32,(3,3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(layers.Conv2D(32,(3,3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# Use max pooling\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# 2 additional hidden 2D convolutional layers\n",
    "model.add(layers.Conv2D(32,(3,3), padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Conv2D(32,(3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# Use max pooling once more\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "# Flatten max filtered output into feature vector \n",
    "# and feed into dense layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Outputs from dense layer are projected onto 10 unit output layer\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay = 1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "if not(data_augmentation):\n",
    "    history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (x_test, y_test),\n",
    "    shuffle = True)  \n",
    "else:  \n",
    "    datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "    \n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=int(50000/batch_size), epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "history_dict = history.history\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12), dpi= 80)\n",
    "\n",
    "ax1.plot(history_dict['loss'], 'o--', label='Training')\n",
    "ax1.plot(history_dict['val_loss'], 'o--', label='Validation')\n",
    "ax1.set_xlabel('Number of Epocs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax2.plot(history_dict['acc'], 'o--', label='Training')\n",
    "ax2.plot(history_dict['val_acc'], 'o--', label='Validation')\n",
    "ax2.set_xlabel('Number of Epocs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3",
   "language": "python",
   "name": "deepml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
