{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs, though it is still underfitting at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "keras.__version__\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters --------------------------------------------------------------\n",
    "# It takes ~4 minutes to run each epoch, adjust the number to match time left\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation --------------------------------------------------------\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load the data\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "\n",
    "# Scale RGB values in test and train images, convert to float 32 first, then divide by 255.0  \n",
    "x_train = \n",
    "x_test = \n",
    "\n",
    "# convert the labels to categorical data\n",
    "y_train = \n",
    "y_test = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model ----------------------------------------------------------\n",
    "# check the python cheatsheet for help\n",
    "\n",
    "# Initialize sequential model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# load sequential model\n",
    "model = \n",
    "\n",
    "# Start with hidden 2D convolutional layer being fed 32x32 pixel images \n",
    "# We need 32 filters, a 3x3 kernel, padding and input shape.\n",
    "# This is followed by an activation layer.\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "# Second hidden layer, as above but only need filter and kernel size, followed by activation layer\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "# Use max pooling (size 2 by 2) and droput (0.25)\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "# 2 additional hidden 2D convolutional and activation layer sets \n",
    "# with 32 filters, 3x3 kernel as well as padding for the first set\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "# Use max pooling and dropout once more, same as above\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "\n",
    "# Flatten max filtered output into feature vector \n",
    "# and feed into dense layer (512), followed by an acrivation and droput layer (0.5)\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "# Outputs from dense layer are projected onto 10 unit dense output layer plus one last activation\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay = 1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "if not(data_augmentation):\n",
    "    history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (x_test, y_test),\n",
    "    shuffle = True)  \n",
    "else:  \n",
    "    datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "    \n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=int(50000/batch_size), epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "history_dict = history.history\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12), dpi= 80)\n",
    "\n",
    "ax1.plot(history_dict['loss'], 'o--', label='Training')\n",
    "ax1.plot(history_dict['val_loss'], 'o--', label='Validation')\n",
    "ax1.set_xlabel('Number of Epocs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax2.plot(history_dict['acc'], 'o--', label='Training')\n",
    "ax2.plot(history_dict['val_acc'], 'o--', label='Validation')\n",
    "ax2.set_xlabel('Number of Epocs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3",
   "language": "python",
   "name": "deepml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
