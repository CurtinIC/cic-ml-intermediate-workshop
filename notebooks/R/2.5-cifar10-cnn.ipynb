{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs, though it is still underfitting at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "library(keras)\n",
    "use_condaenv(\"r-tensorflow\")\n",
    "use_session_with_seed(7)\n",
    "options(keras.view_metrics = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters --------------------------------------------------------------\n",
    "# It takes ~4 minutes to run each epoch, adjust the number to match time left\n",
    "batch_size <- 32\n",
    "epochs <- 2\n",
    "data_augmentation <- TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "# See ?dataset_cifar10 for more info\n",
    "cifar10 <- dataset_cifar10()\n",
    "\n",
    "# Scale RGB values in test and train images, convert to float 32 first, then divide by 255\n",
    "x_train <- \n",
    "x_test <- \n",
    "\n",
    "# convert the labels to categorical data with 10 classes\n",
    "y_train <- \n",
    "y_test <- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model ----------------------------------------------------------\n",
    "\n",
    "# Initialize sequential model\n",
    "model <- \n",
    "\n",
    "model %>%\n",
    "\n",
    "# Start with hidden 2D convolutional layer being fed 32x32 pixel images \n",
    "# We need 32 filters, a 3x3 kernel, padding and input shape.\n",
    "# This is followed by an activation layer.\n",
    "layer_conv_2d(     ) %>%\n",
    "layer_activation() %>%\n",
    "\n",
    "# Second hidden layer, as above but only need filter and kernel size, followed by activation layer\n",
    "layer_conv_2d() %>%\n",
    "layer_activation() %>%\n",
    "\n",
    "# Use max pooling (2x2) and dropout (0.25)\n",
    "layer_max_pooling_2d() %>%\n",
    "layer_dropout() %>%\n",
    "\n",
    "# 2 additional hidden 2D convolutional and activation layer sets \n",
    "# as above, however no more input shape required\n",
    "layer_conv_2d() %>%\n",
    "layer_activation() %>%\n",
    "layer_conv_2d() %>%\n",
    "layer_activation() %>%\n",
    "\n",
    "# Use max pooling and dropout once more, same as above\n",
    "layer_max_pooling_2d() %>%\n",
    "layer_dropout() %>%\n",
    "\n",
    "# Flatten max filtered output into feature vector \n",
    "# feed into dense layer (512), followed by an activation and droput layer (0.5)\n",
    "layer_flatten() %>%\n",
    "layer_dense() %>%\n",
    "layer_activation() %>%\n",
    "layer_dropout() %>%\n",
    "\n",
    "# Outputs from dense layer are projected onto 10 unit output layer\n",
    "# plus one last activation layer (softmax)\n",
    "layer_dense() %>%\n",
    "layer_activation()\n",
    "\n",
    "opt <- optimizer_rmsprop(lr = 0.0001, decay = 1e-6)\n",
    "\n",
    "model %>% compile(\n",
    "loss = \"categorical_crossentropy\",\n",
    "optimizer = opt,\n",
    "metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "\n",
    "if(!data_augmentation){\n",
    "  \n",
    "  history <- model %>% fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = list(x_test, y_test),\n",
    "    shuffle = TRUE\n",
    "  )\n",
    "  \n",
    "} else {\n",
    "  \n",
    "  datagen <- image_data_generator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = TRUE\n",
    "  )\n",
    "  \n",
    "  datagen %>% fit_image_data_generator(x_train)\n",
    "  \n",
    "  history <- model %>% fit_generator(\n",
    "    flow_images_from_data(x_train, y_train, datagen, batch_size = batch_size),\n",
    "    steps_per_epoch = as.integer(50000/batch_size), \n",
    "    epochs = epochs, \n",
    "    validation_data = list(x_test, y_test)\n",
    "  )\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
